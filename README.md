# 批量联系方式爬取与群发工具

## 项目概述

这是一个可以批量爬取多个网站联系方式（邮箱、电话等），并通过SMTP协议群发邮件的工具。整体通过Web界面进行交互，部署在Streamlit上，便于使用与管理。

## 功能特点

### 1. 网站批量导入与处理
- 支持手动输入网址
- 支持上传 `.txt` 或 `.csv` 文件（每行一个网址，或CSV中包含"URL"列）
- 自动去重、校验格式，确保网址有效性

### 2. 联系方式提取模块
- 提取邮箱地址（支持多种域名，尝试从文本、`mailto`链接及部分HTML属性中提取）
- **增强电话号码提取：** 通过更严格的正则表达式，显著减少误识别的数字串（如日期、普通数字），提高电话号码的准确性。
- **全面且分类的社交媒体链接提取：** 扩展了对主流社交媒体平台的识别范围，并能将提取到的链接按平台（如 Facebook, LinkedIn, YouTube, Twitter 等）分类存储和展示，更清晰直观。
- 检测"联系我们"、"关于我们"、"FAQ"等相关页面链接，并进行进一步爬取

### 3. 数据展示与导出
- 表格形式直观展示爬取结果 (URL, 邮箱, 电话, 联系页面, **分类后的社交链接**, 错误信息)
- 可将爬取结果导出为CSV格式文件

### 4. 邮件群发功能
- 使用SMTP协议群发邮件，需在侧边栏配置SMTP服务器信息
- 支持自定义邮件主题和内容模板，模板中可使用 `{website_name}` (网站名称) 和 `{url}` (完整网址) 进行个性化
- 提供每日发送上限和发送间隔设置，以规避邮件服务商限制和垃圾邮件风险
- 显示邮件发送成功/失败统计及详细日志，并支持日志导出

## 安装步骤

1.  **克隆项目到本地：**
    ```bash
    git clone [https://github.com/yourusername/website-contact-crawler.git](https://github.com/yourusername/website-contact-crawler.git)
    cd website-contact-crawler
    ```

2.  **安装依赖：**
    确保您的Python环境已准备就绪，然后安装 `requirements.txt` 中列出的所有库：
    ```bash
    pip install -r requirements.txt
    ```

3.  **运行应用：**
    在项目根目录下运行以下命令启动Streamlit应用：
    ```bash
    streamlit run app.py
    ```
    应用将在您的浏览器中自动打开（通常是 `http://localhost:8501`）。

## 使用说明

1.  **上传网站列表**：
    -   在“上传网站列表”选项卡中，您可以通过“从文件导入”（支持 `TXT` 或 `CSV` 文件）或“手动输入”方式添加待爬取的网址。
    -   请确保网址格式正确，建议包含 `http://` 或 `https://` 前缀。

2.  **爬取联系方式**：
    -   切换到“爬取联系方式”选项卡。
    -   点击“开始爬取联系方式”按钮。程序将自动访问您提供的网站及其关联的联系页面，提取邮箱、电话、社交媒体链接等信息。
    -   爬取过程和结果将实时显示在页面上。
    -   **重要提示：** 本工具主要依赖解析网页的静态HTML内容。对于大量使用JavaScript动态加载内容的网站，可能无法获取到所有联系方式（尤其是邮箱）。若遇到此类情况，请理解为当前技术栈的局限性。

3.  **邮件群发**：
    -   在侧边栏“系统配置”中，首先填写您的SMTP服务器信息（如Gmail的 `smtp.gmail.com` 和端口 `587`），以及发件人邮箱和密码（或授权码），然后点击“测试SMTP配置”按钮验证连接。
    -   切换到“邮件群发”选项卡。
    -   设置邮件主题和内容模板。模板中可使用 `{website_name}` 和 `{url}` 占位符进行自动替换。
    -   设置每日发送上限和每封邮件的发送间隔。
    -   点击“开始群发邮件”按钮，系统将根据爬取到的邮箱地址发送邮件。

4.  **导出数据与日志**：
    -   在“爬取联系方式”选项卡下方，可以点击“导出数据”按钮将爬取到的联系信息保存为CSV文件。
    -   在“邮件群发”完成后，下方会显示发送日志，可以点击“导出发送日志”按钮将其保存为CSV文件。

## 依赖库

-   `streamlit`: 构建Web应用界面
-   `requests`: 发送HTTP请求，获取网页内容
-   `beautifulsoup4`: 解析HTML和XML文档
-   `pandas`: 处理和管理数据（DataFrame）
-   `email-validator`: 邮箱格式验证
-   `validators`: 通用数据验证
-   `smtplib`: Python标准库，用于SMTP邮件发送

## 注意事项与风险提示

-   **法律合规性**：请遵守当地及国际相关的法律法规，**切勿将本工具用于发送垃圾邮件、钓鱼或其他非法用途**。
-   **IP封锁**：爬取速度过快或频率过高可能会被目标网站识别为恶意行为，导致您的IP地址被暂时或永久封锁。请合理设置爬取延迟。
-   **邮件服务商限制**：使用个人邮箱的SMTP服务进行大量群发邮件（特别是无限制发送）非常容易被邮件服务商（如Gmail、QQ邮箱等）识别为异常行为，可能导致发件功能被限制、暂停，甚至邮箱账号被封禁。**强烈建议控制每日发送量，并拉长发送间隔。**
-   **JavaScript动态内容限制**：本工具依赖于解析网站的静态HTML内容。对于那些大量使用JavaScript动态加载联系信息（如邮箱、电话）的网站，本工具可能无法获取到这些信息。这是基于`requests`和`BeautifulSoup`的爬虫的固有局限性。
-   **隐私保护**：在进行任何形式的邮件营销前，请确保您已获得收件人的明确同意，并遵守相关隐私政策（如GDPR、CCPA等）。